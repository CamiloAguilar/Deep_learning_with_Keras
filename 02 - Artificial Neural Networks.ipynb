{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial neural networks\n",
    "\n",
    "### Learning Objectives\n",
    "In this lesson you will learn about:\n",
    "\n",
    "* [Paso 1](#step1): The gradient descent algorithm and how variables are optimized with respect to a defined function.\n",
    "* [Paso 2](#step2): Backpropagation and how neural networks learn and update their weights and biases.\n",
    "* [Paso 3](#step3): The vanishing gradient problem.\n",
    "* [Paso 4](#step4): Activation Functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## 1. Decenso del gradiente\n",
    "![FP](img/02-CostFun.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![FP](img/03-AlgoritmoDG.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![FP](img/04-AlgoritmoDG_iter.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## 2. Backpropagation\n",
    "\n",
    "1. Calcular el error entre el `groung truth`$=T$ y la `salida estimada`. Denótese el error por $E$, el cual representa el costo o la función de pérdida.\n",
    "2. Propagar el error de vuelta en la red y utilizarlo para actualizar cada uno de los `pesos` y el `sesgo` optimizándolo usando las siguientes ecuaciones, las cuales corresponden con el algoritmo de descenso del gradiente:\n",
    "\n",
    "$$ w_i \\rightarrow w_i - \\eta \\cdot \\dfrac{\\partial E}{\\partial w_i}$$\n",
    "\n",
    "\n",
    "$$ b_i \\rightarrow b_i - \\eta \\cdot \\dfrac{\\partial E}{\\partial b_i}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BP](img/05-Backprop_algo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![act](img/06-update_w2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![act](img/06-update_w2_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![act](img/07-update_w1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![act](img/07-update_w1_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![act](img/09-update_b1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ex](img/10-BP_example.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![exp2](img/11-BP_example_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![exp](img/12-BP_example_3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![exa](img/13-BP_example_4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ex](img/14-BP_example_5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ex](img/15-BP_example_6.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo completo de aprendizaje\n",
    "1. Inicializar los pesos y el sesgo de forma `aleatoria`\n",
    "2. Iterativamente repetir los siguientes pasos:\n",
    "    1. Calcular la salida de la red usando `Forward propagation`.\n",
    "    2. Calcular el error entre el `ground truth` y las salidas `estimadas`.\n",
    "    3. Actualizar los `pesos` y el `sesgo` usando `Backpropagation`.\n",
    "    4. Repetir los 3 pasos anteriores hasta alcanzar el número de `iteraciones/epoch` o hasta que el error entre el ground truth y la salida de la predicción esté por debajo del `umbral predefinido`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## 3. Problema de desaparición del gradiente\n",
    "\n",
    "![](img/16-problem_1.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que a medida que avanzamos hacia atrás en el algoritmo de backpropagation, el aprendizaje de cada capa se hace cada vez mas lento, lo cual es causado por el uso de la función de activación sigmoide, puesto que estamos multiplicando una y otra vez valores que se encuentran en el intervalo $(0, 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![prob](img/17-problem_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step4'></a>\n",
    "## 4. Funciones de Activación\n",
    "Las funciones de activación juegan un papel fundamental en el proceso de aprendizaje de una red neuronal. Hasta ahora sólo hemos usado la función sigmoide y hemos visto sus defectos ya que puede llevar a la desaparición del gradiente, para las capas ocultas anteriores.\n",
    "\n",
    "Hay 7 tipos de funciones de activacion que se pueden usar al construir una red neuronal:\n",
    "\n",
    "1. Función de paso binario\n",
    "2. Función lineal\n",
    "3. Función sigmoide\n",
    "4. Función tangente hiperbólica.\n",
    "5. ReLU (Rectified Linear Unit).\n",
    "6. Leaky ReLU.\n",
    "7. Softmax function.\n",
    "\n",
    "Discutiremos 3, 4, 5 y 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/18-activation_fun_1.jpg)\n",
    "![](img/19-activation_fun_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función ``ReLU``** - unidad lineal rectificada** es la función de activación mas utilizada al diseñar redes neuronales hoy en días. Además de no ser lineal, la principal ventaja de usar la función **ReLU** es que no se activan todas las neuronas al mismo tiempo; si la entrada es negativa se convertirá en cero y la neurona por tanto no se activará. Esto significa que a la vez, sólo unas pocas neuronas se activan, haciendo que la red sea mas escasa y eficiente.\n",
    "\n",
    "Además la función **ReLU** resulta ser uno de los avances mas grandes en el campo del **Deep Learning**, que llevó a superar el problema de la desaparición del gradiente.\n",
    "\n",
    "Respecto a la función `softmax` se puede decir que es otro tipo de función sigmoide, pero que es idealmente utilizada en la capa de salida en problemas de clasificación, donde en realidad estamos tratando de obtener la probabilidad de definir la clase de cada entrada, tal como se ve en la imagen anterior. De esta forma resulta mas fácil señalar y determinar a qué categoría pertenece.\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "* Las funciones sigmoide y tangente hiperbólica son evitadas en muchas aplicaciones, ya que pueden conducir al problema de desaparición del gradiente.\n",
    "* La función `ReLU` es una función de activación general y es utilizada en la mayoría de los casos hoy en día.\n",
    "* Nótese que la función `ReLU` sólo debería ser usada en las capas ocultas.\n",
    "* Generalmente, al construir un modelo se puede iniciar utilizando la función `ReLU` y luego puede cambiar a otras funciones de activación si la función `ReLU` no da un buen resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
